{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c41ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importer les modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b337ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "from colorama import Style\n",
    "import os, sys\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from matplotlib.patches import Circle, Wedge, Rectangle\n",
    "from math import log10\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score, precision_score, recall_score \n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "import scipy.stats as stats\n",
    "import shap\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import random\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "import ast\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import metrics\n",
    "from sklearn.inspection import permutation_importance\n",
    "import math\n",
    "from datetime import datetime\n",
    "from datetime import timedelta, date\n",
    "\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pickle\n",
    "from dill import dumps, loads\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da39d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A. IMPORTER LES DONNÉES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Desktop\\Data Science candidature\\Projets\\Projet 7\\Data\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e5f25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4e8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82089d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ac26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "#B. FEATURE ENGINEERING ET CHOIX DE VARIABLES:\n",
    "\n",
    "#B.1 Généralités des datasets.\n",
    "    #a. Le nombre de lignes.\n",
    "\n",
    "    #On a énormément de variables (colonnes) réparties dans 8 datasets. Le 9ème dataset explique la généralité des \n",
    "    #colonnes.\n",
    "\n",
    "    #Notez qu'on a dès le début deux set bien définis:  \n",
    "    # -un pour l'entraînement 'application_train.csv' et \n",
    "    # -un pour le test 'application_test.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('application_train.csv')\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('application_test.csv')\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On a ensuite des dataset qui apportent des information complémentaires, et donc des variables potentiellement\n",
    "    #intéressantes pour l'analyse du risque d'impayés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv('bureau.csv')\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f41fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = pd.read_csv('bureau_balance.csv')\n",
    "\n",
    "print(bb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = pd.read_csv('previous_application.csv')\n",
    "print(prev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "posh = pd.read_csv('POS_CASH_balance.csv')\n",
    "print(posh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a44c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = pd.read_csv('installments_payments.csv')\n",
    "print(ins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af73798",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.read_csv('credit_card_balance.csv')\n",
    "print(cc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10819d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Notez qu'on n'a pas le même nombre de lignes dans tous les datasets, car en fait dans certains d'entre eux on \n",
    "    #split pour chaque client plusieurs lignes, qui correspondent à plusieurs crédits pris ou existants associés au même\n",
    "    #client.\n",
    "    \n",
    "    \n",
    "    #b. Présence de NaN dans les 8 datasets (en pourcentage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc1f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*(df_train.isna().sum()))/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675e154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(100*(df_test.isna().sum()))/len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454affb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(100*(b.isna().sum()))/len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c09381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*(bb.isna().sum()))/len(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977395e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(100*(prev.isna().sum()))/len(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*(posh.isna().sum()))/len(posh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*(ins.isna().sum()))/len(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07914d3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(100*(cc.isna().sum()))/len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31452ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Notez aussi que même si pas toutes les variables ont des NaN on en a beaucoup.\n",
    "\n",
    "    #c.Trouver les colonnes communes entres les 8 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2627ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataset = [df_train, df_test, b, bb, prev, posh, ins, cc]\n",
    "col_common = set.intersection(*(set(df.columns) for df in list_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe20010",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Il faut savoir que les 8 dataset n'ont pas tous de colonnes communes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9be527",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataset = [df_train, df_test, b, prev, posh, ins, cc]\n",
    "col_common = set.intersection(*(set(df.columns) for df in list_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342aa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataset = [b,bb]\n",
    "col_common = set.intersection(*(set(df.columns) for df in list_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed517d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5307120",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #En fait il y en a 7 qui ont comme colonne commune 'SK_ID_CURR': df_train, df_test, b, prev, posh, ins, cc; mais le \n",
    "    #dataset 'bb' n'a pas cette colonne. Néanmoins il a une colonne commune avec le dataset 'b':'SK_ID_BUREAU'.\n",
    "    #Il suffira de matcher 'b' et 'bb' par la colonne 'SK_ID_BUREAU' pour ensuite matcher le résultat avec tous les \n",
    "    #autres dataset grace à la variable: 'SK_ID_CURR'.\n",
    "    \n",
    "    \n",
    "    #d.Type de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6667923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7231588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364839bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fbcdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prev.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "posh.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2befb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Parmi les variables, on en a aux valeurs non numériques mais catégorielles, celles de type 'object' -> on a donc \n",
    "    #besoin de les rendre numériques avec 'One hot encoder'.\n",
    "\n",
    "    #Dans chaque database on a des variables intéressantes que nous garderons et d'autre non avant de faire le merge\n",
    "    #général de tous les datasets. On listera ces variables lors des traitements de chaque dataset.\n",
    "\n",
    "    #Note: DPD -> Days Past Due.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#B.2 Fonctions de traitement des 8 datasets.\n",
    "\n",
    "#B.2.1 Fonction 'One hot encoder' pour les colonnes catégorielles avec 'get_dummies'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.2.2 Prétraitement des bases application_train.csv et application_test.csv.\n",
    "\n",
    "#Regardons les caractéristiques générales de ces deux datasets.\n",
    "\n",
    "    #a. Colonnes communes.\n",
    "    #En regardant le document: 'HomeCredit_columns_description.csv', on dirait que les 2 dataset ont les mêmes colonnes.\n",
    "    #Vérifions quand même ceci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac708eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eadf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np. intersect1d(df_train. columns, df_test. columns).tolist()\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d24254",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Non, les deux dataset n'ont pas les mêmes colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=df_train.columns.values.tolist()\n",
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b872644",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(aa) - set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TARGET'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e19a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Le dataset de 'train' a en plus la colonne 'TARGET'. On n'éliminera néanmoins pas cette colonne même si elle n'est \n",
    "    #pas présente dans le 'test' set, car elle nous permettra d'identifié le train set du test set, le test étant celui\n",
    "    #qui aura la variable 'TARGET' non renseignée. En plus, cette variable 'TARGET' est notre cible, car d'après le\n",
    "    #fichier 'HomeCredit_columns_description', elle identifie les clients avec des difficultés de paiement  (1) des \n",
    "    #autres clients (0).NOTEZ que 'TARGET' ne prends que 2 valeurs 'O' ou '1'.\n",
    "    \n",
    "    \n",
    "    #b. Nombre de lignes des deux datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train samples: {}, test samples: {}\".format(len(df_train), len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #c.Nombre de colonnes à variables catégorielles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9900be5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h=list(df_train.select_dtypes(['object']).columns)\n",
    "len(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'Variable':['NAME_CONTRACT_TYPE','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','OCCUPATION_TYPE','WEEKDAY_APPR_PROCESS_START','ORGANIZATION_TYPE','FONDKAPREMONT_MODE','HOUSETYPE_MODE','WALLSMATERIAL_MODE','EMERGENCYSTATE_MODE'],\n",
    "                    'Elements':[len(set(df_train.NAME_CONTRACT_TYPE)), len(set(df_train.CODE_GENDER)), len(set(df_train.FLAG_OWN_CAR)),len(set(df_train.FLAG_OWN_REALTY)),len(set(df_train.NAME_TYPE_SUITE)),len(set(df_train.NAME_INCOME_TYPE)),len(set(df_train.NAME_EDUCATION_TYPE)),len(set(df_train.NAME_FAMILY_STATUS)),len(set(df_train.NAME_HOUSING_TYPE)),len(set(df_train.OCCUPATION_TYPE)),len(set(df_train.WEEKDAY_APPR_PROCESS_START)),len(set(df_train.ORGANIZATION_TYPE)),len(set(df_train.FONDKAPREMONT_MODE)),len(set(df_train.HOUSETYPE_MODE)),len(set(df_train.WALLSMATERIAL_MODE)),len(set(df_train.EMERGENCYSTATE_MODE))]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c318f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'Variable':['NAME_CONTRACT_TYPE','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','OCCUPATION_TYPE','WEEKDAY_APPR_PROCESS_START','ORGANIZATION_TYPE','FONDKAPREMONT_MODE','HOUSETYPE_MODE','WALLSMATERIAL_MODE','EMERGENCYSTATE_MODE'],\n",
    "                    'Elements':[len(set(df_test.NAME_CONTRACT_TYPE)), len(set(df_test.CODE_GENDER)), len(set(df_test.FLAG_OWN_CAR)),len(set(df_test.FLAG_OWN_REALTY)),len(set(df_test.NAME_TYPE_SUITE)),len(set(df_test.NAME_INCOME_TYPE)),len(set(df_test.NAME_EDUCATION_TYPE)),len(set(df_test.NAME_FAMILY_STATUS)),len(set(df_test.NAME_HOUSING_TYPE)),len(set(df_test.OCCUPATION_TYPE)),len(set(df_test.WEEKDAY_APPR_PROCESS_START)),len(set(df_test.ORGANIZATION_TYPE)),len(set(df_test.FONDKAPREMONT_MODE)),len(set(df_test.HOUSETYPE_MODE)),len(set(df_test.WALLSMATERIAL_MODE)),len(set(df_test.EMERGENCYSTATE_MODE))]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['CODE_GENDER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['CODE_GENDER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59181b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #La variable 'CODE_GENDER' dans le 'train' dataset a 4 lignes avec pour valeur 'XNA', on doit les effacer.\n",
    "\n",
    "    #Par ailleurs, on a trois variables catégorielles binaires: 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY'. On a \n",
    "    #déjà vu 'CODE_GENDER', regardons les duex autres ('FLAG_OWN_CAR', 'FLAG_OWN_REALTY')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619685d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['FLAG_OWN_CAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['FLAG_OWN_CAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['FLAG_OWN_REALTY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['FLAG_OWN_REALTY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3569aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On confirme qu'elles sont bien binaires. \n",
    "    \n",
    "    #Note: On n'a que 'CODE_GENDER' et 'NAME_INCOME_TYPE' qui n'ont pas le même nombre de unique values, entre le \n",
    "    #'train' et le 'test' sets. Pour 'NAME_INCOME_TYPE', il se peut que l'on n'ai pas une catégorie parmi le 'test' set\n",
    "    #mais pour le 'CODE_GENDER', la valeur 'XNA' étant associé uniquement à 4 lignes dans le 'train' set on peut la\n",
    "    #considérer comme une 'erreur', ce qui justifie l'élimination de ces 4 lignes.\n",
    "\n",
    "    #d. Valeurs aberrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377b631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbcbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérifions qu'on n'a pas de ID communs entre le 'train' et le 'test' sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c60d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ID=df_train.merge(df_test, on='SK_ID_CURR')\n",
    "common_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On n'en n'a pas.\n",
    "    \n",
    "    #En regardant les tableaux précédents 'DAYS_EMPLOYED' a une valeur aberrante. En fait toutes ses valeurs sont \n",
    "    #'négatives' (ie. car c'est les jours 'avant la demande de crédit'), sauf une le 'max' qui est trop hors contexte et\n",
    "    #donc à remplacer par 'nan'.\n",
    "\n",
    "    #On calculera aussi des variables plus parlantes, décrivant des pourcentages.\n",
    "\n",
    "\n",
    "    #e. Fonction à associer à ces deux datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6baab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_train_test(num_rows = None, nan_as_category = False):\n",
    "    \n",
    "    df = pd.read_csv('application_train.csv', nrows= num_rows)\n",
    "    df_test = pd.read_csv('application_test.csv', nrows= num_rows)\n",
    "    \n",
    "    # Élimination de la colonne 'TARGET'. (ON NE LE FAIT PAS).\n",
    "    #df.drop('TARGET', inplace=True, axis=1)\n",
    "    \n",
    "    ##Identification des parties train et test.\n",
    "    #df['Train_Test']=1\n",
    "    #df_test['Train_Test']=0\n",
    "    \n",
    "    # Fusion (merge) des deux base.\n",
    "    df = df.append(df_test).reset_index(drop=True)\n",
    "    # On enlève 4 lignes qui uniquement dans la base 'train' ont 'XNA' dans le 'CODE_GENDER'.\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Rendre numériques les variables catégorielles.\n",
    "    # Variables catégorielles binaires (ie. ayant uniquement 2 catégories).\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "        \n",
    "   # On utilise One-Hot encode pour les autres variable catégorielles.\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # Attribution de la valeur NaN pour le 'max' de DAYS_EMPLOYED: 365243 -> nan.\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    # Calculs de variables plus parlantes (percentages).\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "\n",
    "    #gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f15e5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=application_train_test()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e265027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.2.3 Prétraitement des database b et bb.\n",
    "\n",
    "#Regardons les caractéristiques générales de ces datasets.\n",
    "\n",
    "    #a. Nombre de variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db38d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0=list(b.select_dtypes(['object']).columns)\n",
    "len(h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96fac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_1=list(bb.select_dtypes(['object']).columns)\n",
    "len(h0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43274487",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93813dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'Variable':['CREDIT_ACTIVE','CREDIT_CURRENCY','CREDIT_TYPE'],\n",
    "                    'Elements':[len(set(b.CREDIT_ACTIVE)), len(set(b.CREDIT_CURRENCY)), len(set(b.CREDIT_TYPE))]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8bf890",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'Variable':['STATUS'],\n",
    "                    'Elements':[len(set(bb.STATUS))]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47268ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On a respectivement 3 et 1 colonnes catégorielles dans b et bb, soit 4 au total suite au merge.\n",
    "    \n",
    "    \n",
    "    #b. Valeurs abérrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d34d05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c55818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On n'a pas de valeurs aberrantes qui ressortent directement.\n",
    "    \n",
    "    \n",
    "    #c. Aspect général."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a483c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca03889a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Dans ces 2 bases de données on a plusieurs lignes associées à un même client il faut donc prendre les moyennes, min et\n",
    "    #max, var, sum... selon les variables. On utilise pour ce faire la fonction aggregate() qui permet d'exécuter une \n",
    "    #fonction ou une liste de fonctions le long d'un des axes du DataFrame (par défaut 0 -> lignes).\n",
    "\n",
    "\n",
    "    #d. Fonction à associer à ces deux datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    b = pd.read_csv('bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('bureau_balance.csv', nrows = num_rows)\n",
    "    \n",
    "    # Rendre numériques les variables catégorielles de bureau (b) et bureau_balance (bb).\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    b, b_cat = one_hot_encoder(b, nan_as_category)\n",
    "    \n",
    "    # Bureau balance (bb): Aggregations et merge avec bureau.csv (b).\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    b = b.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    b.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Variables numériques de bureau (b) et bureau_balance (bb). \n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Features catégorielles de bureau (b) et bureau_balance (bb). \n",
    "    cat_aggregations = {}\n",
    "    for cat in b_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    b_agg = b.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    b_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in b_agg.columns.tolist()])\n",
    "    \n",
    "    # Identification des crédits actifs -> on utilise une 'numerical aggregation'.\n",
    "    active = b[b['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    b_agg = b_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Identification des crédits clos -> on utilise une 'numerical aggregation'.\n",
    "    closed = b[b['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    b_agg = b_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg\n",
    "    \n",
    "    gc.collect()\n",
    "    return b_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334df18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_agg=bureau_and_balance()\n",
    "b_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.2.4 Prétraitement de la base previous_applications.csv (prev).\n",
    "\n",
    "#Regardons les caractéristiques générales de ce dataset.\n",
    "\n",
    "    #a. Nombre de variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1=list(prev.select_dtypes(['object']).columns)\n",
    "len(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e299e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51badf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'Variable':['NAME_CONTRACT_TYPE','WEEKDAY_APPR_PROCESS_START','FLAG_LAST_APPL_PER_CONTRACT','NAME_CASH_LOAN_PURPOSE','NAME_CONTRACT_STATUS','NAME_PAYMENT_TYPE','CODE_REJECT_REASON','NAME_TYPE_SUITE','NAME_CLIENT_TYPE','NAME_GOODS_CATEGORY','NAME_PORTFOLIO','NAME_PRODUCT_TYPE','CHANNEL_TYPE','NAME_SELLER_INDUSTRY','NAME_YIELD_GROUP','PRODUCT_COMBINATION'],\n",
    "                    'Elements':[len(set(prev.NAME_CONTRACT_TYPE)), len(set(prev.WEEKDAY_APPR_PROCESS_START)), len(set(prev.FLAG_LAST_APPL_PER_CONTRACT)),len(set(prev.NAME_CASH_LOAN_PURPOSE)),len(set(prev.NAME_CONTRACT_STATUS)),len(set(prev.NAME_PAYMENT_TYPE)),len(set(prev.CODE_REJECT_REASON)),len(set(prev.NAME_TYPE_SUITE)),len(set(prev.NAME_CLIENT_TYPE)),len(set(prev.NAME_GOODS_CATEGORY)),len(set(prev.NAME_PORTFOLIO)),len(set(prev.NAME_PRODUCT_TYPE)),len(set(prev.CHANNEL_TYPE)),len(set(prev.NAME_SELLER_INDUSTRY)),len(set(prev.NAME_YIELD_GROUP)),len(set(prev.PRODUCT_COMBINATION))]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a81ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On a une seule variable binaire 'FLAG_LAST_APPL_PER_CONTRACT'.\n",
    "    \n",
    "    \n",
    "    #b. Valeurs abérrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c097282",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #En regardant les tableaux précédents les variables: 'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', \n",
    "    #'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE' et 'DAYS_TERMINATION' ont une valeur aberrante. En fait toutes leurs \n",
    "    #valeurs sont toutes 'négatives' (ie. car c'est les jours 'avant la demande de crédit'), sauf une: leur 'max' qui \n",
    "    #est trop hors contexte et donc à remplacer par 'nan'.\n",
    "    \n",
    "    \n",
    "    #c. Aspect général."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f9709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Dans cette base de données un client peut avoir 0, 1, 2 demandes de prêt précédentes ou plus dans le Home Credit\n",
    "    #(information obtenue du document: 'HomeCredit_columns_description'); il faut donc prendre les moyennes, min et max,\n",
    "    #var, sum... selon les variables. On utilise pour ce faire la fonction aggregate() qui permet d'exécuter une \n",
    "    #fonction ou une liste de fonctions le long d'un des axes du DataFrame (par défaut 0 -> lignes).\n",
    "\n",
    "    #On calculera aussi des variables plus parlantes, décrivant des pourcentages.\n",
    "\n",
    "\n",
    "    #d. Fonction à associer à ces deux datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad761f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    \n",
    "    prev = pd.read_csv('previous_application.csv', nrows = num_rows)\n",
    "    \n",
    "    # Rendre numériques les variables catégorielles.\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    \n",
    "    # Attribution de la valeur NaN pour le 'max' des 5 variables avec valeur aberrante: 365243 -> nan.\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    # Création de la variable 'APP_CREDIT_PERC' (pourcentage de crédit reçu) : value ask / value received percentage.\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    \n",
    "    # Variables numériques de previous_applications (prev).\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    \n",
    "    # Variables catégorielles de previous_applications (prev).\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    \n",
    "    # Identification des applications approuvées.\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    #  Identification des applications refusées.\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg\n",
    "    \n",
    "    gc.collect()\n",
    "    return prev_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84b6a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prev_agg=previous_applications()\n",
    "prev_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.2.5 Prétraitement de la base POS_CASH_balance.csv (posh).\n",
    "\n",
    "#Regardons les caractéristiques générales de ce dataset.\n",
    "\n",
    "    #a. Nombre de variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2=list(posh.select_dtypes(['object']).columns)\n",
    "len(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5278fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'Variable':['NAME_CONTRACT_STATUS'],\n",
    "                    'Elements':[len(set(posh.NAME_CONTRACT_STATUS))]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8dc7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On a une seule variable catégorielle.\n",
    "    \n",
    "    \n",
    "    #b. Valeurs aberrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf7e23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "posh.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef45e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On n'a pas de valeurs aberrantes qui ressortent directement.\n",
    "    \n",
    "    \n",
    "    #c. Aspect général."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1398b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf4a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Dans cette base de données un client peut avoir 0, 1, 2 demandes de prêt précédentes ou plus dans le Home Credit\n",
    "    #(information obtenue du document: 'HomeCredit_columns_description'); il faut donc prendre les moyennes, min et max,\n",
    "    #var, sum... selon les variables. On utilise pour ce faire la fonction aggregate() qui permet d'exécuter une \n",
    "    #fonction ou une liste de fonctions le long d'un des axes du DataFrame (par défaut 0 -> lignes).\n",
    "\n",
    "    #On calculera aussi des variables plus parlantes, décrivant des pourcentages.\n",
    "\n",
    "\n",
    "    #d. Fonction à associer à ces deux datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260127ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    \n",
    "    posh = pd.read_csv('POS_CASH_balance.csv', nrows = num_rows)\n",
    "    \n",
    "    # Rendre numériques les variables catégorielles.\n",
    "    posh, cat_cols = one_hot_encoder(posh, nan_as_category= True)\n",
    "    \n",
    "    # Variables numériques de pos_cash (posh).\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = posh.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    \n",
    "    # Nombre de comptes pos_cash.\n",
    "    pos_agg['POS_COUNT'] = posh.groupby('SK_ID_CURR').size()\n",
    "   \n",
    "    gc.collect()\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5acb6fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_agg=pos_cash()\n",
    "pos_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc37f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.2.6 Prétraitement de la base installments_payments.csv (ins).\n",
    "\n",
    "#Regardons les caractéristiques générales de ce dataset.\n",
    "\n",
    "    #a. Nombre de variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3=list(ins.select_dtypes(['object']).columns)\n",
    "len(h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Il n'y a pas de variables catégorielles.\n",
    "    \n",
    "    \n",
    "    #b. Valeurs aberrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c2f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On n'a pas de valeurs aberrantes qui ressortent directement.\n",
    "    \n",
    "    \n",
    "    #c. Aspect général."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdda2d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Dans cette base de données un client peut avoir 0, 1, 2 demandes de prêt précédentes ou plus dans le Home Credit\n",
    "    #(information obtenue du document: 'HomeCredit_columns_description'); il faut donc prendre les moyennes, min et max,\n",
    "    #var, sum... selon les variables. On utilise pour ce faire la fonction aggregate() qui permet d'exécuter une \n",
    "    #fonction ou une liste de fonctions le long d'un des axes du DataFrame (par défaut 0 -> lignes).\n",
    "\n",
    "    #On calculera aussi des variables plus parlantes, décrivant des pourcentages.\n",
    "\n",
    "\n",
    "    #d. Fonction à associer à ces deux datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74636d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    \n",
    "    ins = pd.read_csv('installments_payments.csv', nrows = num_rows)\n",
    "\n",
    "    # Rendre numériques les variables catégorielles.\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    \n",
    "    # Pourcentage et différence payés à chaque versement (montant payé et valeur du versement).\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    \n",
    "    # Days past due and days before due (valeurs non negatives).\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "    \n",
    "    # Variables numériques de installments_payments (ins).\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    \n",
    "    # Nombre de installments accounts.\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "   \n",
    "    gc.collect()\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f75a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ins_agg=installments_payments()\n",
    "ins_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36847150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.2.7 Prétraitement de la base credit_card_balance.csv (cc).\n",
    "\n",
    "#Regardons les caractéristiques générales de ce dataset.\n",
    "\n",
    "    #a. Nombre de variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ba682",
   "metadata": {},
   "outputs": [],
   "source": [
    "h4=list(cc.select_dtypes(['object']).columns)\n",
    "len(h4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fe883",
   "metadata": {},
   "outputs": [],
   "source": [
    "h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eed80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'Variable':['NAME_CONTRACT_STATUS'],\n",
    "                    'Elements':[len(set(cc.NAME_CONTRACT_STATUS))]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def11aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On a une seule variable catégorielle.\n",
    "    \n",
    "    \n",
    "    #b. Valeurs aberrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae95f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad05231",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On n'a pas de valeurs aberrantes qui ressortent directement.\n",
    "    \n",
    "    \n",
    "    #c. Aspect général."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf9b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Dans cette base de données un client peut avoir 0, 1, 2 demandes de prêt précédentes ou plus dans le Home Credit\n",
    "    #(information obtenue du document: 'HomeCredit_columns_description'); il faut donc prendre les moyennes, min et max,\n",
    "    #var, sum... selon les variables. On utilise pour ce faire la fonction aggregate() qui permet d'exécuter une \n",
    "    #fonction ou une liste de fonctions le long d'un des axes du DataFrame (par défaut 0 -> lignes).\n",
    "\n",
    "    #On calculera aussi des variables plus parlantes, décrivant des pourcentages.\n",
    "\n",
    "\n",
    "    #d. Fonction à associer à ces deux datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    \n",
    "    cc = pd.read_csv('credit_card_balance.csv', nrows = num_rows)\n",
    "\n",
    "    # Rendre numériques les variabkes catégorielles.\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    \n",
    "     # Variables numériques de credit_card_balance (cc).\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    \n",
    "    #Nombre de lignes de carte de crédit. \n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "\n",
    "    gc.collect()\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a5409",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc_agg=credit_card_balance()\n",
    "cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.3 Fusion des différent datasets traités.\n",
    "\n",
    "    #Notez que l'on peut faire la fusion sans crainte car on a déjà vérifié que les datasets (autres que b, bb, \n",
    "    #df_train et df_test) avaient comme unique variable commune 'SK_ID_CURR'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318bb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.join(b_agg, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.join(prev_agg, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.join(pos_agg, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a028dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.join(ins_agg, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.join(cc_agg, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On a:\n",
    "    \n",
    "    #Pour les colonnes:\n",
    "    #-df (et donc df_1) -> 248 colonnes\n",
    "    #-b_agg -> 116 colonnes\n",
    "    #-prev_agg -> 249 colonnes\n",
    "    #-pos_agg -> 18 colonnes\n",
    "    #-ins_agg -> 26 colonnes\n",
    "    #-cc_agg -> 141 colonnes\n",
    "\n",
    "    #Soit la somme de toutes les colonnes -> les 798 colonnes que l'on retrouve bien.\n",
    "    \n",
    "    #Pour les lignes, on en a 356251, qui correspondent au nombre de 'SK_ID_CURR'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*(df_1.isna().sum()))/len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*(df_1['TARGET'].isna().sum()))/len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c18e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_1.columns[df_1.isna().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On a énormément de variables avec des NAN (résultant de nos variables initiales avec NAN).\n",
    "    #La variable 'TARGET' à presque 14% de NaN, mais c'est des NaN qui nous permettent de distinguer le 'train' et le\n",
    "    #'test' sets. Il faudra conserver les NaN de la colonne 'TARGET'.\n",
    "    \n",
    "#B.4 Élimination des NaN.\n",
    "#Comme ce ne sont pas des données faciles à remplir à titre d'expert ou en établissant des règles de gestion (ie. on ne \n",
    "#peut pas les inventer), on éliminera directement les colonnes ayant plus de X% de NAN.\n",
    "    \n",
    "#On aurait pu le faire dès le début, mais on décide de le faire maintenant car il était important de faire apparaître,\n",
    "#lors des traitements des bases de données les \"variables plus parlantes à dire d'expert\". En fait, si on avait \n",
    "#éliminer dès le début toutes les variables ayant plus de 10% de NAN, certaines de ces 'variables parlantes à dire\n",
    "#d'expert' n'auraient pas été listées.\n",
    "    \n",
    "#Voyons combien de colonnes ont plus de 50% de NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = (100*(df_1.isna().sum()))/len(df_1)\n",
    "col_to_drop1 = null_percentage[null_percentage>50]\n",
    "len(col_to_drop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf414db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voyons combien de colonnes ont plus de 50% de NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop2 = null_percentage[null_percentage>60]\n",
    "len(col_to_drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voyons combien de colonnes ont plus de 10% de NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8884b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop3 = null_percentage[null_percentage>10]\n",
    "len(col_to_drop3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voyons combien de colonnes ont plus de 5% de NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53688a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop4 = null_percentage[null_percentage>4]\n",
    "len(col_to_drop4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voyons combien de colonnes ont plus de 1% de NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop5 = null_percentage[null_percentage>1]\n",
    "len(col_to_drop5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voyons combien de colonnes ont plus de 0% de NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9016973",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop6 = null_percentage[null_percentage>0]\n",
    "len(col_to_drop6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d170359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On pourra littéralement éliminer les colonnes qui on plus de 4 pourcent de NaN, pour garder une idée d'avoir une \n",
    "#population à 99% propre de NaN. (En fait c'est le même nombre de colonnes à éliminer pour 4% et pour 1%). Et on \n",
    "#éliminera le 1% des lignes aui resteront avec des NaN.\n",
    "    \n",
    "#On rappelle le fait que l'on ne veut pas enlever la colonne 'TARGET' (vue son importance et pour identifier le 'train' \n",
    "#du 'test' set, et surtout étant la variable cible qui identifie les clients avec (1) et sans(0) difficultés de \n",
    "#paiement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2742d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del col_to_drop5['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6197f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop5=col_to_drop5.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e4d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.drop(col_to_drop5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd57f1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voyons quelles sont les colonnes qui ont encore des NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ca7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=df_2[df_2.columns[df_2.isnull().any()]]\n",
    "aa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3367169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_percentage_2 = (100*(df_2.isna().sum()))/len(df_2)\n",
    "col_to_drop7 = null_percentage_2[null_percentage_2>0]\n",
    "col_to_drop7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Effaçons les NaN qui restent. Sauf ceux de la colonne 'TARGET'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75527d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del col_to_drop7['TARGET']\n",
    "col_to_drop7=col_to_drop7.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd3cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=df_2.copy()\n",
    "df_3=pd.DataFrame(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ea3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=df_3.dropna(subset=col_to_drop7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c671d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=df_3[df_3.columns[df_3.isnull().any()]]\n",
    "bb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#null_percentage_3 = (100*(df_3.isna().sum()))/len(df_3)\n",
    "#col_to_drop8 = null_percentage_3[null_percentage_3>0].keys()\n",
    "#col_to_drop8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['TARGET'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.5 Doublons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dublons=df_3.duplicated(subset=['SK_ID_CURR']).sum()\n",
    "dublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notez qu'il n'y a pas de doublons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.6 Identification des 'train' et 'test' sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_3=df_3[df_3['TARGET'].notnull()]\n",
    "train_df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Vérifions encore une fois qu'on n'a plus de NAN dans le 'train' set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=train_df_3[train_df_3.columns[train_df_3.isnull().any()]]\n",
    "cc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d54cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_3=df_3[df_3['TARGET'].isnull()]\n",
    "test_df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400840c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Vérifions encore une fois qu'on n'a plus de NAN dans le 'test' set (mis appart ceux du 'TARGET')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38cdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=test_df_3[test_df_3.columns[test_df_3.isnull().any()]]\n",
    "dd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fe2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.7 Quelques statistiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de256e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in train_df_3.columns if f not in ['SK_ID_CURR','TARGET']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877477bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_stats = train_df_3[feats].describe()\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87461464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.8 Normalisation des données.\n",
    "\n",
    "#Il est recommandé de normaliser les variables qui ont différentes échelles (cf. statistiques en haut). En fait, \n",
    "#même si le modèle peut converger sans normalisation ça rend l'entraînement plus difficile et le résultat dépendant \n",
    "#des unités utilisées pour les variables.\n",
    "\n",
    "#Notez que nous avons générer les statistiques précédentes uniquement sur le \"set training\", ces statistiques sont \n",
    "#également utilisées pour normaliser l'ensemble de données de test, ceci car l'ensemble de données de test doivent \n",
    "#être projetées dans la même distribution que celle sur laquelle le training fut fait.\n",
    "\n",
    "#On a décidé de ne pes normaliser la variable cible ('TARGET'). En fait ceci n'est pas vraiment nécessaire, et en \n",
    "#plus il s'agit d'un variable binaire.\n",
    "\n",
    "#On a parmi nos variables, des variables qui permettent uniquement d'identifier les clients: 'SK_ID_CURR',\n",
    "#et 'index'; elles on ne les normalise pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    A=(x[feats] - train_stats['mean']) / train_stats['std']\n",
    "    A['TARGET']=x['TARGET']\n",
    "    #A['SK_ID_CURR']=x['SK_ID_CURR']\n",
    "    \n",
    "    return A \n",
    "train_df_n = norm(train_df_3)\n",
    "test_df_n = norm(test_df_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58734a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_stats_n = train_df_n.describe()\n",
    "train_stats_n = train_stats_n.transpose()\n",
    "train_stats_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_n['TARGET'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_n['TARGET'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96519698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notez qu'on a un data set avec 2 classes déséquilibrées: ayant ~91.91% de 'sains' et ~8.9% de défauts.\n",
    "\n",
    "#Vérifions encore une fois qu'on n'a plus de NAN dans le 'train' et le 'test' set normalisé (mis appart 'TARGET' pour \n",
    "#le 'test' set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40bb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee=train_df_n[train_df_n.columns[train_df_n.isnull().any()]]\n",
    "ee.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f827ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=test_df_n[test_df_n.columns[test_df_n.isnull().any()]]\n",
    "ff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visiblement on a 2 colonnes avec des 'NAN' suite à la normalisation. Il faut comprendre pourquoi, voyons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7918af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_3['FLAG_MOBIL'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_3['FLAG_MOBIL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bec1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_3['NAME_FAMILY_STATUS_Unknown'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_3['NAME_FAMILY_STATUS_Unknown'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On voit que pour ces deux variables en fait on a une seule valeur, elles n'apportent donc rien, on peut les éliminer.\n",
    "#Et ce du 'train' et du 'test' sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_n=train_df_n.drop(['FLAG_MOBIL', 'NAME_FAMILY_STATUS_Unknown'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_n=test_df_n.drop(['FLAG_MOBIL', 'NAME_FAMILY_STATUS_Unknown'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérifions encore une fois qu'on n'a plus de NAN dans le 'train' et le 'test' set normalisé (mis appart 'TARGET' pour \n",
    "#le 'test' set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee1=train_df_n[train_df_n.columns[train_df_n.isnull().any()]]\n",
    "ee1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f67784",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff1=test_df_n[test_df_n.columns[test_df_n.isnull().any()]]\n",
    "ff1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C'est bon pour ce qui est des NAN et de la Normalisation.\n",
    "\n",
    "#Rajoutons le 'SK_ID_CURR'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_n=train_df_n.join(train_df_3['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6aba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e64961",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_n=test_df_n.join(test_df_3['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63552ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_n=test_df_n.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.9 Identification de la variable cible ('TARGET')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fe170",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cible_n = train_df_n.pop('TARGET')\n",
    "test_cible_n = test_df_n.pop('TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c47b095",
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENTION: Il ne faut pas que les features (ie. les noms des colonnes aient de caractères JSON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebbcaf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df_n.columns = train_df_n.columns.str.replace(\"[,]\", \"_\")\n",
    "train_df_n.columns = train_df_n.columns.str.replace(\"[[]]\", \"_\")\n",
    "train_df_n.columns = train_df_n.columns.str.replace(\"[:]\", \"_\")\n",
    "train_df_n.columns = train_df_n.columns.str.replace(\"[{}]\", \"_\")\n",
    "train_df_n.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfa5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_n.columns = test_df_n.columns.str.replace(\"[,]\", \"_\")\n",
    "test_df_n.columns = test_df_n.columns.str.replace(\"[[]]\", \"_\")\n",
    "test_df_n.columns = test_df_n.columns.str.replace(\"[:]\", \"_\")\n",
    "test_df_n.columns = test_df_n.columns.str.replace(\"[{}]\", \"_\")\n",
    "test_df_n.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base complète:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ea2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_complete=train_df_n\n",
    "Base_complete=pd.DataFrame(Base_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbff34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_complete = Base_complete.append(test_df_n).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5568cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportons la base complète en format CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b073fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_complete.to_csv(r'C:\\Users\\'titite\\Desktop\\Data Science candidature\\Projets\\Projet 7\\Data\\Base_complete.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3388d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour des raison de taille avec Heroku, afin de pouvoir travailler dans la version non payante, on fera les tests sur \n",
    "#le cloud avec la moitié de la base test. Ce, afin de réduire la mémoire utilisée sur le serveur de Heroku.\n",
    "\n",
    "#Exportons donc une petite partie de la base test en format CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_test=test_df_n\n",
    "Base_test=pd.DataFrame(Base_test)\n",
    "Base_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a946c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On prend donc les 41 premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85fa17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_test1=Base_test.head(41)\n",
    "Base_test1=pd.DataFrame(Base_test1)\n",
    "Base_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832a40b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Base_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_test1.to_csv(r'C:\\Users\\'titite\\Desktop\\Data Science candidature\\Projets\\Projet 7\\Data\\Base_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725fe64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30fb433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf465ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "#C. LES MODÈLES:\n",
    "\n",
    "#Construction et entraînement des modèles.\n",
    "    #Notez que la fonction \".fit\", c'est celle qui est chargée d'entraîner notre modèle et que la fonction \".predict\", \n",
    "    #c'est celle qui est chargée de prédire la variable cible à partir du dataset test.\n",
    "    \n",
    "    #Comme ici le 'test' set n'a pas de 'TARGET' renseignés on utilisera la fonction 'cross_val_score' de 'sklearn',\n",
    "    #pour valider le modèle (ie. pour calculer un AUC plus acurate). En fait, 'cross_val_score', entraîne et teste un \n",
    "    #modèle sur plusieurs plis d'un jeu de données, sans pour autant en retourner un (ie. pas de '.predict' possible \n",
    "    #par la suite). Cette méthode de validation croisée permet de mieux comprendre les performances du modèle sur \n",
    "    #l'ensemble du jeu de données au lieu de le faire sur un seul fractionnement train/test, et nous aide dans les \n",
    "    #situations comme la notre pour tester le modèle.\n",
    "    #De plus, afin de s'assurer que chaque pli de l'ensemble de données a la même proportion d'observations qui font ou \n",
    "    #pas défaut ('TARGET'= 1 et 'TARGET'=0), on utilisera 'StratifiedKFold' de 'sklearn' dans le paramètre 'cv' de \n",
    "    #'cross_val_score'.\n",
    "    \n",
    "    \n",
    "    #Par ailleurs, comme on a un dataset avec un 'TARGET' binaire aux classes déséquilibrées, on fera l'analyse de\n",
    "    #la performance des différents modèles (ie. le calcul de leur AUC), non seulement suite à une 'Cross_Validation'\n",
    "    #et suite à un '.fit/.predict', mais aussi sur deux approches: une première sans et une deuxième avec 'SMOTE'.\n",
    "    \n",
    "    #Le défi de travailler avec des ensembles de données aux classes déséquilibrés est que la plupart des techniques \n",
    "    #d'apprentissage automatique ignorent et, à leur tour, ont de mauvaises performances sur la classe minoritaire, \n",
    "    #et c'est généralement la performance sur la classe minoritaire qui est la plus importante. Une approche pour \n",
    "    #traiter alors les ensembles de données aux classes déséquilibrés consiste à suréchantillonner la classe \n",
    "    #minoritaire. L'approche la plus simple consiste à dupliquer des exemples dans la classe minoritaire, qui \n",
    "    #n'ajoutent aucune nouvelle information au modèle. De nouveaux exemples peuvent être synthétisés à partir des\n",
    "    #exemples existants. Il s'agit d'un type d'augmentation de données pour la classe minoritaire qui est appelée \n",
    "    #SMOTE' (ie. Synthetic Minority Oversampling Technique).\n",
    "    #'SMOTE' du packaging 'imblearn' fait donc en quelque sorte un 'réquilibrage' des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89982c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avec scoring 'roc_auc'.(Dans le cas d’une classification avec des classes deséquilibrées il est suggéré d’utiliser l’AUC).\n",
    "\n",
    "def cross_validation_2(x, y, model):\n",
    "    \n",
    "    start_time_cv = datetime.now()\n",
    "    result= cross_val_score(model, x, y, cv=kfold, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    end_time_cv = datetime.now()\n",
    "    time_cv = end_time_cv - start_time_cv\n",
    "    time=time_cv.seconds\n",
    "    \n",
    "    result_table0 = pd.DataFrame(columns=['classifiers', 'auc'])\n",
    "    result_table0 = result_table0.append({'classifiers':model.__class__.__name__,\n",
    "                                         'auc':result.mean(),\n",
    "                                         'time (s)':time}, ignore_index=True)\n",
    "\n",
    "    print(\"Score: %f\" % result.mean())\n",
    "    return result_table0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------\n",
    "\n",
    "#C.1 Choix du meilleur modèle: SANS 'SMOTE' (ie. sans réquilibrage des classes).\n",
    "#Comparaison des AUC résultant d'une \"Cross_Validation\" et d'un \".fit/.predict\" des différents modèles:\n",
    "\n",
    "\n",
    "#C.1.0 Train et Test sets obtenus du Train set.\n",
    "\n",
    "#Maintenant, comme le dataset 'test' n'a pas de cibles renseignées pour entraîner et tester le modèle on va diviser le \n",
    "#'train' set en 2, une partie pour le training (avec 80% des données) et une partie pour le test (avec 20% des données).\n",
    "#Pour que les deux parties soient équilibrées on utilise la fonction 'train_test_split' de 'sklearn', sur les bases \n",
    "#'train_df_n' et 'train_cible_n', stratifiée sur 'train_cible_n' ('stratify=train_cible_n')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f45ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f579f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cible_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcf4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df_n, train_cible_n, test_size=0.2, random_state=42, stratify=train_cible_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10016dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_test= X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de19b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54963035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C.1.1 Définitions des modèles.\n",
    "\n",
    "#a. DummyRegressor: \n",
    "    #On prend la médiane car elle est statistiquement préférable à la moyenne.\n",
    "    #Sans optimisation des hyperparamètres (pour le DummyRegressor il n'y a pas vraiment des paramètres à optimiser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_E= DummyRegressor(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d12512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.1 AUC résultant d'une 'Cross_Validation'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49960331",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_E_score_auc = cross_validation_2(X_train, y_train, DM_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e729c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DM_E_score_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.2  AUC résultant d'un '.fit/.predict'.\n",
    "\n",
    "#Entraînement du modèle ('.fit')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2972ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_E = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2521ffd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DM_E.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee74df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_E = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60011bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_time_E = end_time_E - start_time_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45fad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prédiction ('.predict')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_prediction_E=DM_E.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_DM_E=roc_auc_score(y_test,DM_prediction_E)\n",
    "AUC_DM_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notez que la valeur du roc_auc est de 0.5 ce qui dit que le modèle est non-informatif.\n",
    "\n",
    "#------\n",
    "\n",
    "\n",
    "#b. LGBMClassifier.\n",
    "\n",
    "#Light GBM utilise un algorithme d'apprentissage basé sur un arbre qui grandit verticalement (ie. par feuille) \n",
    "#contrairement à d'autres algorithmes qui font grandir l'arbre horizontalement (ie. par niveau). Il est don plus rapide,\n",
    "#ce qui le rend très utile pour de grands datasets.\n",
    "\n",
    "#Les hyperparamètres intéressant à être modifiés sont:\n",
    "# -'learning_rate': Impact de chaque arbre sur le résultat final. GBM fonctionne en commençant par une estimation \n",
    "#                   initiale qui est mise à jour à l'aide de la sortie de chaque arbre. Le paramètre d'apprentissage \n",
    "#                   contrôle l'ampleur de ce changement dans les estimations.\n",
    "\n",
    "# -'num_leaves': Nombre de feuilles dans l'arbre complet.\n",
    "\n",
    "# -'min_child_samples': Nombre minimum de données nécessaires dans une feuille.\n",
    "\n",
    "# -'n_estimators': Nombre d'arbres boostés à adapter.\n",
    "\n",
    "\n",
    "#Pour faire l'optimisation des hyperparamètres on utilise 'GridSearchCV' de 'sklearn'.\n",
    "\n",
    "#b.1 Obtention des meilleurs hyperparamètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc869532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters_lgb = {'learning_rate':[0.2,0.1,0.01,0.05,0.001],'num_leaves':range(10,100,10),'min_child_samples':range(500,1000,100),'n_estimators':range(50,300,50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb= GridSearchCV(estimator = LGBMClassifier(), param_grid = parameters_lgb, cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb9e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06108576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients obtenus par le \"meilleur\" modèle (ie. celui avec les \"meilleurs hyperparamètres\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_best = LGBMClassifier(learning_rate=0.05, num_leaves=70, min_child_samples=800,  n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af42875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.2 AUC résultant d'une 'Cross_Validation'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_score_auc = cross_validation_2(X_train, y_train, lgb_best)\n",
    "lgb_score_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notez que la valeur du roc_auc est de l'ordre de 0.74 ce qui dit que le modèle est assez bon, assez informatif.\n",
    "\n",
    "\n",
    "#------\n",
    "\n",
    "#c. XGBClassifier\n",
    "\n",
    "#Les hyperparamètres intéressant à être modifiés sont:\n",
    "# -'learning_rate': Impact de chaque arbre sur le résultat final. GBM fonctionne en commençant par une estimation \n",
    "#                   initiale qui est mise à jour à l'aide de la sortie de chaque arbre. Le paramètre d'apprentissage \n",
    "#                   contrôle l'ampleur de ce changement dans les estimations\n",
    "\n",
    "# -'subsample': Compris entre 0 et 1 c'est le ratio d'échantillonnage pour le training. Par exemple, le régler sur 0,5 \n",
    "#               signifie que XGBoost échantillonnerait au hasard la moitié des données.\n",
    "\n",
    "# -'max_depth': Profondeur maximale d'un arbre. L'augmentation de cette valeur rendra le modèle plus complexe et plus \n",
    "#               susceptible de overfit. 0 indique aucune limite de profondeur.\n",
    "\n",
    "# -'n_estimators': Nombre d'arbres boostés à adapter.\n",
    "\n",
    "\n",
    "#Pour faire l'optimisation des hyperparamètres on utilise 'GridSearchCV' de 'sklearn'.\n",
    "\n",
    "#c.1 Obtention des meilleurs hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd95f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters_xgbc = {learning_rate':[0.2,0.1,0.01,0.05,0.001],'subsample':[1,0.5,0.2,0.1],'max_depth' : range(2,11,1),'n_estimators':range(50,300,50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29abc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbc= GridSearchCV(estimator = XGBClassifier(), param_grid = parameters_xgbc, cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac37ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#xgbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1512ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients obtenus par le \"meilleur\" modèle (ie. celui avec les \"meilleurs hyperparamètres\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_best = XGBClassifier(learning_rate=0.2, max_depth=4, n_jobs=-1, random_state=100,scale_pos_weight=11.387150050352467)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d1d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.2 AUC résultant d'une 'Cross_Validation'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_xgbc = cross_validation_2(X_train, y_train, xgbc_best)\n",
    "scores_xgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2940b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C.1.2 Comparaison des modèles. \n",
    "\n",
    "#a. AUC résultant d'une 'Cross_Validation'. (sur les meilleurs hyperparamètres pour LGBMClassifier et XGBClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp=DM_E_score_auc\n",
    "df_comp=pd.DataFrame(df_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24403ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp=df_comp.append(lgb_score_auc, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp=df_comp.append(scores_xgbc, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23407d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On voit bien que le LGBMClassifier est le meilleur modèle (ie. celui ayant le meilleur AUC),lorsqu'on utilise la \n",
    "#méthode de \"cross_validation\". Vérifions ceci en utilisant \".fit\".\n",
    "\n",
    "\n",
    "#b. AUC résultant d'un '.fit/.predict'. (sur les meilleurs hyperparamètres pour LGBMClassifier et XGBClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aaaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [ lgb_best,xgbc_best]\n",
    "\n",
    "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc','time(s)'])\n",
    "result_table2 = pd.DataFrame(columns=['classifiers', 'auc','time(s)'])\n",
    "result_table3 = pd.DataFrame(columns=['classifiers', 'auc','accuracy', 'precision','recall','time(s)'])\n",
    "\n",
    "for cls in classifiers:\n",
    "    start_time= datetime.now()\n",
    "    model = cls.fit(X_train, y_train)\n",
    "    end_time= datetime.now()\n",
    "    \n",
    "    #Il est nécessaire de calculer les 'probabilités' d'occurrence car on a des données non équilibrées (ie. plus de 1 que de 0).    \n",
    "    yproba = model.predict_proba(X_test)[::,1] \n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "    auc = roc_auc_score(y_test, yproba)\n",
    "    time= end_time - start_time\n",
    "    time2=time.seconds\n",
    "    \n",
    "    accuracy=accuracy_score(y_test, model.predict(X_test))\n",
    "    precision=precision_score(y_test, model.predict(X_test))\n",
    "    recall=recall_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':auc,\n",
    "                                        'time(s)':time}, ignore_index=True)\n",
    "    \n",
    "    result_table2 = result_table2.append({'classifiers':cls.__class__.__name__,\n",
    "                                         'auc':auc,\n",
    "                                         'time(s)':time2}, ignore_index=True)\n",
    "    \n",
    "    result_table3 = result_table3 .append({'classifiers':cls.__class__.__name__,\n",
    "                                         'auc':auc,\n",
    "                                         'accuracy':accuracy,\n",
    "                                         'precision':precision,\n",
    "                                         'recall':recall,\n",
    "                                         'time(s)':time2}, ignore_index=True)\n",
    "\n",
    "\n",
    "result_table.set_index('classifiers', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENTION: \n",
    "#Dans les paramètre de la 'roc_curve', 'pos_label' indique la valeur associée à la 'classe positive'. Lorsque \n",
    "#'pos_label=None', 'pos_label' vaut 1.\n",
    "\n",
    "#Ainsi, nous le défaut est représenté par 1, du coup l'état de 'défaut' est notre classe positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a355c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table2.loc[2] = ['DummyRegressor', AUC_DM_E, DM_time_E.seconds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996716ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table2_2=result_table2.reindex([2,0,1])\n",
    "result_table2_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6940b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0905020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c. Graphique des courbes ROC_AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for i in result_table.index:\n",
    "    plt.plot(result_table.loc[i]['fpr'], \n",
    "             result_table.loc[i]['tpr'], \n",
    "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc'])\n",
    "             )\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040142c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notez que le meilleur modèle est le LGBMClassifier, ayant le meilleur AUC (ie. le plus proche de 1), comme la montrent\n",
    "#le tableau et le graphique. Ceci confirme les résultats obtenus en faisant en utilisant \"cross_validation\". \n",
    "\n",
    "\n",
    "#C.1.3 Probabilités prédites par le meilleur modèle: 'LGBMClassifier'.\n",
    "\n",
    "#a. Sur le 'train set' (qui est le seul qui la colonne 'TARGET' remplie, et du coup sur lequel on se base)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d31d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cible_predLGB=lgb_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13d0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, lgb_best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e701cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENTION:\n",
    "#Précision-> une métrique qui quantifie le nombre de prédictions 'positives' correctes faites (ie. ici le nombre \n",
    "#            de défauts correctement prédits).\n",
    "#            C'est le rapport des exemples positifs correctement prédits divisé par le nombre total d'exemples positifs \n",
    "#            qui ont été prédits:\n",
    "#            Précision = TruePositives / (TruePositives + FalsePositives)\n",
    "#            Si 0-> aucune précision,\n",
    "#            Si 1 -> précision totale ou parfaite -> minimise les faux positifs (ie. ici les faux défauts)\n",
    "#            'combien d'éléments sont correctement classés dans cette classe'.\n",
    "\n",
    "#Recall-> une métrique qui quantifie le nombre de prédictions positives correctes faites sur toutes les prédictions \n",
    "#         positives qui auraient pu être faites.\n",
    "#         c'est le rapport des exemples positifs correctement prédits divisé par le nombre total d'exemples positifs \n",
    "#         qui pourraient être prédits:\n",
    "#         Rappel = TruePositives / (TruePositives + FalseNegatives)\n",
    "#         Si 0 -> aucun rappel, si 1 ->rappel complet ou parfait -> minimise les faux négatifs (ie. ici les faux sains)\n",
    "#         'combien d'éléments d'une classe on été trouvés sur le nombre total d'élément constituant cette classe'.\n",
    "\n",
    "\n",
    "#Dans notre cas on a un problème avec le recall, qui doit être dû au caractère déséquilibré de nos classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a22b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Proba_train = pd.DataFrame({'SK_ID_CURR': X_test['SK_ID_CURR'],'Defaut':y_test,'Predict_Defaut':lgb_best.predict(X_test),'Proba': lgb_best.predict_proba(X_test)[:,1]})\n",
    "Proba_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculons la matrice de confusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=y_test\n",
    "y_pred=lgb_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "cf_matrix=confusion_matrix(y_true, y_pred)\n",
    "\n",
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "  \n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaaa571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. sur le 'test set':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39fe18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cible_predLGB=lgb_best.predict(test_df_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Proba_test = pd.DataFrame({'SK_ID_CURR': test_df_n.SK_ID_CURR, 'Proba': lgb_best.predict_proba(test_df_n)[:,1]})\n",
    "Proba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02025921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------\n",
    "\n",
    "#C.2 Choix du meilleur modèle: AVEC 'SMOTE' (ie. avec réquilibrage des classes).\n",
    "#Comparaison des AUC résultant d'une \"Cross_Validation\" et d'un \".fit/.predict\" des différents modèles.\n",
    "\n",
    "#Commençons par appliquer le 'SMOTE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c83da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label 1, Before using SMOTE: {} \".format(sum(train_cible_n==1)))\n",
    "print(\"Label 0, Before using SMOTE: {} \".format(sum(train_cible_n==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_req, train_cible_req = sm.fit_resample(train_df_n,train_cible_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc39236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENTION le 'SMOTE' on peut le faire uniquement sur le 'train' set, car on a besoin d'avoir la variable 'TARGET'\n",
    "#définie. Néanmoins, on appliquera le résultat du '.fit' sur le 'train' set  'smoté' pour faire le '.predict'sur le\n",
    "#'test' set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label 1, After using SMOTE: {}\".format(sum(train_cible_req==1)))\n",
    "print(\"Label 0, After using SMOTE: {}\".format(sum(train_cible_req==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C.2.0 Train et Test sets obtenus du Train set.\n",
    "\n",
    "#Maintenant, comme le dataset 'test' n'a pas de cibles renseignées pour entraîner et tester le modèle on va diviser le \n",
    "#'train' set en 2, une partie pour le training (avec 80% des données) et une partie pour le test (avec 20% des données).\n",
    "#Pour que les deux parties soient équilibrées on utilise la fonction 'train_test_split' de 'sklearn', sur les bases \n",
    "#'train_df_n' et 'train_cible_n', stratifiée sur 'train_cible_n' ('stratify=train_cible_n')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2280cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_req.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cible_req.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec5eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_req, X_test_req, y_train_req, y_test_req = train_test_split(train_df_req, train_cible_req, test_size=0.2, random_state=42, stratify=train_cible_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe916864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_req.shape, X_test_req.shape, y_train_req.shape, y_test_req.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_req=X_train_req.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_req=X_test_req.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_req=y_train_req.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b93214",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_req=y_test_req.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvegardons ces bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd51db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_req.to_csv(r'C:\\Users\\'titite\\Desktop\\Data Science candidature\\Projets\\Projet 7\\Data\\X_train_req_saved.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de04b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_req.to_csv(r'C:\\Users\\'titite\\Desktop\\Data Science candidature\\Projets\\Projet 7\\Data\\X_test_req_saved.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_req.to_csv(r'C:\\Users\\'titite\\Desktop\\Data Science candidature\\Projets\\Projet 7\\Data\\y_train_req_saved.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c434f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_req.to_csv(r'C:\\Users\\'titite\\Desktop\\Data Science candidature\\Projets\\Projet 7\\Data\\y_test_req_saved.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C.2.1 Définitions des modèles.\n",
    "\n",
    "#a. DummyRegressor: \n",
    "    #On prend la médiane car elle est statistiquement préférable à la moyenne.\n",
    "    #Sans optimisation des hyperparamètres (pour le DummyRegressor il n'y a pas vraiment des paramètres à optimiser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_E= DummyRegressor(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30619c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.1 AUC résultant d'une 'Cross_Validation'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_E_score_auc_req = cross_validation_2(X_train_req, y_train_req, DM_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68145b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DM_E_score_auc_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0549a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.2  AUC résultant d'un '.fit/.predict'.\n",
    "\n",
    "#Entraînement du modèle ('.fit')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220de159",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_E_req = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2966a89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DM_E.fit(X_train_req, y_train_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_E_req = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_time_E_req = end_time_E_req - start_time_E_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83909bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prédiction ('.predict')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8d0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_prediction_E_req=DM_E.predict(X_test_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_DM_E_req=roc_auc_score(y_test_req,DM_prediction_E_req)\n",
    "AUC_DM_E_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce047efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notez que la valeur du roc_auc est de 0.5 ce qui dit que le modèle est non-informatif.\n",
    "\n",
    "#------\n",
    "\n",
    "\n",
    "#b. LGBMClassifier.\n",
    "\n",
    "#Light GBM utilise un algorithme d'apprentissage basé sur un arbre qui grandit verticalement (ie. par feuille) \n",
    "#contrairement à d'autres algorithmes qui font grandir l'arbre horizontalement (ie. par niveau). Il est don plus rapide, ce\n",
    "#qui le rend très utile pour de grands datasets.\n",
    "\n",
    "#Les hyperparamètres intéressant à être modifiés sont:\n",
    "# -'learning_rate': Impact de chaque arbre sur le résultat final. GBM fonctionne en commençant par une estimation \n",
    "#                   initiale qui est mise à jour à l'aide de la sortie de chaque arbre. Le paramètre d'apprentissage \n",
    "#                   contrôle l'ampleur de ce changement dans les estimations\n",
    "\n",
    "# -'num_leaves': Nombre de feuilles dans l'arbre complet.\n",
    "\n",
    "# -'min_child_samples': Nombre minimum de données nécessaires dans une feuille.\n",
    "\n",
    "# -'n_estimators': Nombre d'arbres boostés à adapter.\n",
    "\n",
    "\n",
    "#Pour faire l'optimisation des hyperparamètres on utilise 'GridSearchCV' de 'sklearn'.\n",
    "\n",
    "#b.1 Obtention des meilleurs hyperparamètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dfa261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters_lgb = {'learning_rate':[0.2,0.1,0.01,0.05,0.001],'num_leaves':range(10,100,10),'min_child_samples':range(500,1000,100),'n_estimators':range(50,300,50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb= GridSearchCV(estimator = LGBMClassifier(), param_grid = parameters_lgb, cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2482df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lgb.fit(X_train_req, y_train_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients obtenus par le \"meilleur\" modèle (ie. celui avec les \"meilleurs hyperparamètres\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_best = LGBMClassifier(learning_rate=0.05, num_leaves=70, min_child_samples=800,  n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.2 AUC résultant d'une 'Cross_Validation'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f432b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_score_auc_req = cross_validation_2(X_train_req, y_train_req, lgb_best)\n",
    "lgb_score_auc_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notez que la valeur du roc_auc est de l'ordre de 0.74 ce qui dit que le modèle est assez bon, assez informatif.\n",
    "\n",
    "\n",
    "#------\n",
    "\n",
    "#c. XGBClassifier.\n",
    "\n",
    "#Les hyperparamètres intéressant à être modifiés sont:\n",
    "# -'learning_rate': Impact de chaque arbre sur le résultat final. GBM fonctionne en commençant par une estimation \n",
    "#                   initiale qui est mise à jour à l'aide de la sortie de chaque arbre. Le paramètre d'apprentissage \n",
    "#                   contrôle l'ampleur de ce changement dans les estimations.\n",
    "\n",
    "# -'subsample': Compris entre 0 et 1 c'est le ratio d'échantillonnage pour le training. Par exemple, le régler sur 0,5 \n",
    "#               signifie que XGBoost échantillonnerait au hasard la moitié des données.\n",
    "\n",
    "# -'max_depth': Profondeur maximale d'un arbre. L'augmentation de cette valeur rendra le modèle plus complexe et plus \n",
    "#               susceptible de overfit. 0 indique aucune limite de profondeur.\n",
    "\n",
    "# -'n_estimators': Nombre d'arbres boostés à adapter.\n",
    "\n",
    "\n",
    "#Pour faire l'optimisation des hyperparamètres on utilise 'GridSearchCV' de 'sklearn'.\n",
    "\n",
    "#c.1 Obtention des meilleurs hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84dd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters_xgbc = {learning_rate':[0.2,0.1,0.01,0.05,0.001],'subsample':[1,0.5,0.2,0.1],'max_depth' : range(2,11,1),'n_estimators':range(50,300,50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8778e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbc= GridSearchCV(estimator = XGBClassifier(), param_grid = parameters_xgbc, cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d99d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#xgbc.fit(X_train_req, y_train_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9260515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients obtenus par le \"meilleur\" modèle (ie. celui avec les \"meilleurs hyperparamètres\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_best = XGBClassifier(learning_rate=0.2, max_depth=4, n_jobs=-1, random_state=100,scale_pos_weight=11.387150050352467)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c.2 AUC résultant d'une 'Cross_Validation'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_xgbc_req = cross_validation_2(X_train_req, y_train_req, xgbc_best)\n",
    "scores_xgbc_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C.1.2 Comparaison des modèles. \n",
    "\n",
    "#a. AUC résultant d'une 'Cross_Validation'. (sur les meilleurs hyperparamètres pour LGBMClassifier et XGBClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42281333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_req=DM_E_score_auc_req\n",
    "df_comp_req=pd.DataFrame(df_comp_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1501ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_req=df_comp_req.append(lgb_score_auc_req, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_req=df_comp_req.append(scores_xgbc_req, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc957c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On voit bien que le LGBMClassifier est le meilleur modèle (ie. celui ayant le meilleur AUC), lorsqu'on utilise la \n",
    "#méthode de \"cross_validation\". Vérifion ceci en utilisant \".fit\".\n",
    "\n",
    "\n",
    "#b. AUC résultant d'un '.fit/.predict'. (sur les meilleurs hyperparamètres pour LGBMClassifier et XGBClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [lgb_best, xgbc_best]\n",
    "\n",
    "result_table_req = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc','time(s)'])\n",
    "result_table2_req = pd.DataFrame(columns=['classifiers', 'auc','time(s)'])\n",
    "result_table3_req = pd.DataFrame(columns=['classifiers', 'auc','accuracy', 'precision','recall','time(s)'])\n",
    "\n",
    "for cls in classifiers:\n",
    "    start_time_req= datetime.now()\n",
    "    model = cls.fit(X_train_req, y_train_req)\n",
    "    end_time_req= datetime.now()\n",
    "    \n",
    "    #Il est nécessaire de calculer les 'probabilités' d'occurrence car on a des données non équilibrées (ie. plus de 1 que de 0).    \n",
    "    yproba = model.predict_proba(X_test_req)[::,1] \n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test_req,  yproba)\n",
    "    auc = roc_auc_score(y_test_req, yproba)\n",
    "    time_req= end_time_req - start_time_req\n",
    "    time2_req=time_req.seconds\n",
    "    \n",
    "    accuracy=accuracy_score(y_test_req, model.predict(X_test_req))\n",
    "    precision=precision_score(y_test_req, model.predict(X_test_req))\n",
    "    recall=recall_score(y_test_req, model.predict(X_test_req))\n",
    "    \n",
    "    result_table_req = result_table_req.append({'classifiers':cls.__class__.__name__,\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':auc,\n",
    "                                        'time(s)':time_req}, ignore_index=True)\n",
    "    \n",
    "    result_table2_req = result_table2_req.append({'classifiers':cls.__class__.__name__,\n",
    "                                         'auc':auc,\n",
    "                                         'time(s)':time2_req}, ignore_index=True)\n",
    "    \n",
    "    result_table3_req = result_table3_req.append({'classifiers':cls.__class__.__name__,\n",
    "                                         'auc':auc,\n",
    "                                         'accuracy':accuracy,\n",
    "                                         'precision':precision,\n",
    "                                         'recall':recall,\n",
    "                                         'time(s)':time2_req}, ignore_index=True)\n",
    "\n",
    "\n",
    "result_table_req.set_index('classifiers', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94fa22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENTION: \n",
    "#Dans les paramètre de la 'roc_curve', 'pos_label' indique la valeur associée à la 'classe positive'. Lorsque \n",
    "#'pos_label=None', 'pos_label' vaut 1.\n",
    "\n",
    "#Ainsi, nous le défaut est représenté par 1, du coup l'état de 'défaut' est notre classe positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table2_req.loc[2] = ['DummyRegressor', AUC_DM_E_req, DM_time_E_req.seconds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ac2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table2_req_2=result_table2_req.reindex([2,0,1])\n",
    "result_table2_req_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table3_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1044923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c. Graphique des courbes ROC_AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for i in result_table_req.index:\n",
    "    plt.plot(result_table_req.loc[i]['fpr'], \n",
    "             result_table_req.loc[i]['tpr'], \n",
    "             label=\"{}, AUC={:.3f}\".format(i, result_table_req.loc[i]['auc'])\n",
    "             )\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b037c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notez que le meilleur modèle est le LGBMClassifier, ayant le meilleur AUC (ie. le plus proche de 1), comme la montrent\n",
    "#le tableau et le graphique. Ceci confirme les résultats obtenus en faisant en utilisant \"cross_validation\". \n",
    "\n",
    "\n",
    "#C.1.3 Probabilités prédites par le meilleur modèle: 'LGBMClassifier'.\n",
    "\n",
    "#a. Sur le 'train set' (qui est le seul qui la colonne 'TARGET' remplie, et du coup sur lequel on se base)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dd325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_best.fit(X_train_req, y_train_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cible_predLGB=lgb_best.predict(X_test_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d44412",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_req, lgb_best.predict(X_test_req)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ef44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENTION:\n",
    "#Précision-> une métrique qui quantifie le nombre de prédictions 'positives' correctes faites (ie. ici le nombre \n",
    "#            de défauts correctement prédits).\n",
    "#            C'est le rapport des exemples positifs correctement prédits divisé par le nombre total d'exemples positifs \n",
    "#            qui ont été prédits:\n",
    "#            Précision = TruePositives / (TruePositives + FalsePositives)\n",
    "#            Si 0-> aucune précision,\n",
    "#            Si 1 -> précision totale ou parfaite -> minimise les faux positifs (ie. ici les faux défauts)\n",
    "#            'combien d'éléments sont correctement classés dans cette classe'\n",
    "\n",
    "#Recall-> une métrique qui quantifie le nombre de prédictions positives correctes faites sur toutes les prédictions \n",
    "#         positives qui auraient pu être faites.\n",
    "#         c'est le rapport des exemples positifs correctement prédits divisé par le nombre total d'exemples positifs \n",
    "#         qui pourraient être prédits:\n",
    "#         Rappel = TruePositives / (TruePositives + FalseNegatives)\n",
    "#         Si 0 -> aucun rappel, si 1 ->rappel complet ou parfait -> minimise les faux négatifs (ie. ici les faux sains)\n",
    "#         'combien d'éléments d'une classe on été trouvés sur le nombre total d'élément constituant cette classe'\n",
    "\n",
    "\n",
    "#En réquilibrant les classes avec 'SMOTE' le problème du 'Recall' est résolu.\n",
    "\n",
    "#Sauvegardons donc ce modèle:\n",
    "#NOTE: Pour el sauvegarder une fois le meilleur modèle choisit et entraîné, on utilise le packaging 'Pickle'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdfa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvegardons le modèle entraîné comme un pickle string.\n",
    "\n",
    "#create an iterator object with write permission - model.pkl\n",
    "with open('model_pkl', 'wb') as files:\n",
    "    pickle.dump(lgb_best, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explorons un peu les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd9888",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Proba_train_req = pd.DataFrame({'SK_ID_CURR': X_test_req['SK_ID_CURR'],'Defaut':y_test_req,'Predict_Defaut (.predict)':lgb_best.predict(X_test_req),'Proba': lgb_best.predict_proba(X_test_req)[:,1]})\n",
    "Proba_train_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc149989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculons la matrice de confusion:\n",
    "#Obtenue en faisant le '.predict' et donc en donnant le même poids au Faux Positifs et aux Faux Négatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_req=y_test_req\n",
    "y_pred_req=lgb_best.predict(X_test_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f79abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "cf_matrix=confusion_matrix(y_true_req, y_pred_req)\n",
    "\n",
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "  \n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803199b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. sur le 'test set':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6fe834",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cible_predLGB=lgb_best.predict(test_df_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64222f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Proba_test_req = pd.DataFrame({'SK_ID_CURR': test_df_n.SK_ID_CURR, 'Proba': lgb_best.predict_proba(test_df_n)[:,1]})\n",
    "Proba_test_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C.3 Fonction de coût métier.\n",
    "\n",
    "#Note: On rappelle que Positif=défaut et négatif=sain.\n",
    "\n",
    "#Dans le domaine du crédit, les faux négatifs (ie. ici les faux sains) sont plus coûteux, on veut donc les diminuer, ou\n",
    "#autrement dit, leur donner moins de poids.\n",
    "\n",
    "#On décide d'utiliser la fonction 'fbeta_score' de 'Sklearn', car elle permet de donner moins de poids au \n",
    "#'Faux négatifs' (ie. contreparties faussement notées comme saines, c'est à dire contreparties qui en vrai son en \n",
    "#défaut mais sont notées comme saines) qui sont moins coûteux que les 'Faux Positifs' (ie les contreparties faussement \n",
    "#notées en défaut, c'est à dire contreparties qui en vrai sont saines mais sont notées en défaut).\n",
    "\n",
    "#Un score F-bêta > 0.85 est considéré comme un excellent score, un score fbeta > 0,7 comme un bon et tout autre score \n",
    "#comme un mauvais. \n",
    "\n",
    "#Quant au coefficient 'β', il se définit comme:\n",
    "\n",
    "#                                 β = Cost of False Negative/Cost of False Positive.\n",
    "\n",
    "\n",
    "#le choix de β, qui est donc à définir par l'expertise métier, déterminera le poids que l'on souhaite donner à chacune \n",
    "#des deux mesures:\n",
    "# -β<1 -> privilégie la précision (si β=0 , alors F_β=Précision)-> minimise les faux positifs (ie. ici les faux défauts)\n",
    "# -β>1 -> privilégie le recall -> minimise les faux négatifs (ie. ici les faux sains).\n",
    "\n",
    "#Nous on préfère avoir plus de faux positifs (ie. clients mis en défauts alors qu'ils ne le sont pas) que de faux \n",
    "#négatifs (ie. clients non mis en défaut qui devraient l'être). Si l'on veut minimiser les faux négatifs, on\n",
    "#sélectionnera un β supérieur à 1 (ie. un fort rappel implique un faible taux de faux négatifs).\n",
    "\n",
    "#Ainsi si le Coût d'un Faux Négatif (un défaut classifié comme sain) est de 30% de la valeur du crédit, et que le coût\n",
    "#d'un Faux Positif (un sain qui se voit refuser le crédit car classifié négatif) et de 10% (en fait c'est 3 fois moins \n",
    "#coûteux qu'un défaut qui obtient le crédit), on peut prendre β=3. Il reste donc à trouver le meilleur threshold (seuil)\n",
    "#associé à ce β (ie. celui qui donne le meilleur fbeta score, le maximum fbeta score).\n",
    "\n",
    "#Voyons quel est le couplet (β, threshold) qui donne le meilleur 'fbeta_score':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_probs=lgb_best.predict_proba(X_test_req)[:,1] #On prend les résultats obtenus de la partie 'test' du training set.\n",
    "\n",
    "f0_5_scores = []\n",
    "f1_scores = []\n",
    "f1_5_scores = []\n",
    "f2_scores = []\n",
    "f2_5_scores = []\n",
    "f3_scores = []\n",
    "f4_scores = []\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Définition des seuils (ie. threshold) de probabilité à utiliser, entre 0 et 1.\n",
    "probability_thresholds = np.linspace(0, 1, num=100)\n",
    "\n",
    "# Trouver des scores pour chaque seuil (ie. threshold).\n",
    "for p in probability_thresholds:\n",
    "    \n",
    "    y_test_preds = []\n",
    "    \n",
    "    for prob in y_test_probs:\n",
    "        if prob > p:\n",
    "            y_test_preds.append(1)\n",
    "        else:\n",
    "            y_test_preds.append(0)\n",
    "            \n",
    "    \n",
    "    f0_5 = fbeta_score(y_test_req, y_test_preds, beta=0.5)\n",
    "    f1 = f1_score(y_test_req, y_test_preds)\n",
    "    f1_5 = fbeta_score(y_test_req, y_test_preds, beta=1.5)\n",
    "    f2 = fbeta_score(y_test_req, y_test_preds, beta=2)\n",
    "    f2_5 = fbeta_score(y_test_req, y_test_preds, beta=2.5)\n",
    "    f3 = fbeta_score(y_test_req, y_test_preds, beta=3)\n",
    "    f4 = fbeta_score(y_test_req, y_test_preds, beta=4)\n",
    "    \n",
    "    prec = precision_score(y_test_req, y_test_preds)\n",
    "    rec = recall_score(y_test_req, y_test_preds)\n",
    "        \n",
    "    f0_5_scores.append(f0_5)\n",
    "    f1_scores.append(f1)\n",
    "    f1_5_scores.append(f1_5)\n",
    "    f2_scores.append(f2)\n",
    "    f2_5_scores.append(f2_5)\n",
    "    f3_scores.append(f3)\n",
    "    f4_scores.append(f4)\n",
    "    precision_scores.append(prec)\n",
    "    recall_scores.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bef7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.plot(probability_thresholds, f0_5_scores , label='f0.5')\n",
    "ax.plot(probability_thresholds, f1_scores, label='f1')\n",
    "ax.plot(probability_thresholds, f1_5_scores, label='f1.5')\n",
    "ax.plot(probability_thresholds, f2_scores, label='f2')\n",
    "ax.plot(probability_thresholds, f2_5_scores, label='f2.5')\n",
    "ax.plot(probability_thresholds, f3_scores, label='f3')\n",
    "ax.plot(probability_thresholds, f4_scores, label='f4')\n",
    "ax.plot(probability_thresholds, precision_scores, label='Precision')\n",
    "ax.plot(probability_thresholds, recall_scores, label='Recall')\n",
    "ax.set_xlabel('Probability Threshold')\n",
    "ax.set_ylabel('f-beta score')\n",
    "ax.legend(loc='center right');\n",
    "ax.set_ylim(0.47, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fcc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On voit bien que les valeurs maximales du fbeta score s’obtiennent pour les β plus petits, et donc quand on favorise \n",
    "#la précision (ie. on diminue les Faux Positifs,et donc les Faux Defauts). L'expertise métier ne voulant prioritariser \n",
    "#le recall, si l'on se centre sur le β=3 (élue suite aux explications précédentes des rapports de coûts entre faux \n",
    "#négatifs et faux positifs) on a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac98be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.plot(probability_thresholds, f3_scores, label='f3')\n",
    "ax.plot(probability_thresholds, precision_scores, label='Precision')\n",
    "ax.plot(probability_thresholds, recall_scores, label='Recall')\n",
    "\n",
    "ymax = max(f3_scores)\n",
    "xpos = f3_scores.index(ymax)\n",
    "xmax = probability_thresholds[xpos]\n",
    "text= \"Local max: x={:.3f}, y={:.3f}\".format(xmax, ymax)\n",
    "\n",
    "ax.set_xlabel('Probability Threshold')\n",
    "ax.set_ylabel('f-beta score')\n",
    "ax.legend(loc='center right')\n",
    "ax.set_ylim(0.47, 1.05)\n",
    "\n",
    "ax.annotate(text, xy=(xmax, ymax),xytext=(xmax, ymax-0.05),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c34845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le meilleur seuil (ie. threshold) pour β=3 (lui choisi par expertise métier) est 0.091.\n",
    "#Ainsi tout ce qui est <=0.91 sera mis comme 'sain', et tout ce qui est >0.091 en défaut.\n",
    "\n",
    "#Recalculons alors les Défauts prédits en considérant le 'Coût Métier' (ie. le 'Predict_Defaut_Avec_CM')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Proba_train_req2=Proba_train_req\n",
    "Proba_train_req2=pd.DataFrame(Proba_train_req2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d952fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaut_CM = []\n",
    "\n",
    "for row in Proba_train_req2['Proba']:\n",
    "    if row > 0.091 :defaut_CM.append(1)\n",
    "    else:defaut_CM.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e99fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Proba_train_req2['Predict_Defaut_Avec_CM']=defaut_CM\n",
    "Proba_train_req2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b469fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recalculons le fbeta score obtenu ainsi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_req=y_test_req\n",
    "y_pred_req_avec_CM=Proba_train_req2['Predict_Defaut_Avec_CM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = precision_score(y_true_req, y_pred_req_avec_CM)\n",
    "r = recall_score(y_true_req, y_pred_req_avec_CM)\n",
    "f = fbeta_score(y_true_req, y_pred_req_avec_CM, beta=3)\n",
    "\n",
    "print('Result: p=%.3f, r=%.3f, f=%.3f' % (p, r, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On retrouve bien le fbeta score maximum obtenu pour β=3 et on voit bien qu'on donne ainsi plus de poids au recall\n",
    "#qu'à la précision, diminuant ainsi les 'Faux Négatifs' comme le demande le métier.\n",
    "\n",
    "#Appliquons maintenant cette nouvelles règle sur le 'test set':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adde1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Proba_test_req2=Proba_test_req\n",
    "Proba_test_req2=pd.DataFrame(Proba_test_req2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaut_CM_test_set = []\n",
    "\n",
    "for row in Proba_test_req2['Proba']:\n",
    "    if row > 0.091 :defaut_CM_test_set.append(1)\n",
    "    else:defaut_CM_test_set.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Proba_test_req2['Predict_Defaut_Avec_CM']=defaut_CM_test_set\n",
    "Proba_test_req2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e095fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C.4 Features Importance.\n",
    "\n",
    "#L'importance locale ->se concentre sur la contribution des caractéristiques pour une prédiction spécifique\n",
    "#                    ->pertinente lorsque nous voulons expliquer pourquoi une personne spécifique s'est vu refuser un \n",
    "#                      prêt à partir d'un modèle.\n",
    "\n",
    "#L'importance globale -> prend en compte toutes les prédictions.\n",
    "#                     -> On utilise la fonction '.feature_importances_' associée au 'RandomForestRegressor' de \n",
    "#                       'sklearn.ensemble'.\n",
    "\n",
    "\n",
    "#C.4.1 Features Importance Globale (dépendante de l'algorithme ->.feature_importances_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae529906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Globla_FI=pd.DataFrame(lgb_best.feature_importances_, X_train_req.columns, columns = ['Importance'])\n",
    "\n",
    "#On sélectionne les 40 meilleures features avec le [:20].\n",
    "A=Globla_FI.sort_values(by=['Importance'],ascending=False)[:20] \n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptation pour le code Flask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279dcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Globla_FI2 = pd.Series(lgb_best.feature_importances_,index=X_train_req.columns).sort_values(ascending=False, axis=0)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Globla_FI2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvegardons le \"explainer\" de \"LIME\" comme un pickle string.\n",
    "#Cette fois-ci en utilisant \"dill\", car \"pickel\" ne fonctionne pas avec \"LIME\"\n",
    "\n",
    "#create an iterator object with write permission - expl.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('global_pkl', 'wb') as files:\n",
    "    dill.dump(Globla_FI2, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee25983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ab227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('global_pkl', 'rb') as files:\n",
    "#    glob= dill.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B=glob.sort_values(by=['Importance'],ascending=False)[:20] \n",
    "#B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83421ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "A.plot(kind='bar', ax=ax,legend=False)\n",
    "ax.set_xlabel('20 Best Features', size=15)\n",
    "ax.set_ylabel('Importance', size=15)\n",
    "ax.tick_params(axis='x', labelrotation =90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad920dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notez que c'est la variable 'PAYMENT_RATE' ='AMT_ANNUITY'/'AMT_CREDIT' (ie. Paiement annuel d'une partie du capital \n",
    "#emprunté et des intérêts/ crédit total emprunté), que l'on a crée qui est la plus importante. Lui suivant le \n",
    "#'EXT_SOURCE_2' qui est un score provenant d'une external data source (comme un benchmark) et les 'DAYS_BIRTH'.\n",
    "#Pour ce qui est des 'DAYS_BIRTH' voyons quel est le lien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f08ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Proba_train_req3=Proba_train_req2\n",
    "Proba_train_req3=pd.DataFrame(Proba_train_req3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17146e9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Proba_train_req3['DAYS_BIRTH']=X_test_req['DAYS_BIRTH']\n",
    "Proba_train_req3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd440ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=round(abs(train_df_3['DAYS_BIRTH'])/365)\n",
    "B=pd.DataFrame(B)\n",
    "B['SK_ID_CURR']=train_df_3['SK_ID_CURR']\n",
    "B=B.rename({'DAYS_BIRTH': 'DAYS_BIRTH_2'}, axis=1)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9770be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "D=Proba_train_req3.merge(B, on='SK_ID_CURR')\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1031ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "C=D.loc[:,['Predict_Defaut_Avec_CM', 'DAYS_BIRTH_2']]\n",
    "C.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d67496",
   "metadata": {},
   "outputs": [],
   "source": [
    "C['Age_intervals']=pd.qcut(C['DAYS_BIRTH_2'], q=4)\n",
    "C1=C.loc[:,['Predict_Defaut_Avec_CM', 'Age_intervals']]\n",
    "C2=C1.groupby(['Age_intervals'])['Predict_Defaut_Avec_CM'].sum().reset_index()\n",
    "C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b410976",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "C2.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Age', size=15)\n",
    "ax.set_ylabel('Default rate', size=15)\n",
    "ax.tick_params(axis='x', labelrotation =90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a17fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On voit que ce sont les jeunes ce qui en gros on tendance à être le plus en défaut.\n",
    "\n",
    "\n",
    "#C.4.2 Features Importance Locale (c'est à dire par client -> LIME):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ATTENTION: On n'a pas utilisé SHAP car il a un bug, bug que j'ai signaler sur le github concerné.\n",
    "\n",
    "#X_train_req.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a28139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explainer = shap.Explainer(lgb_best, X_train_req, check_additivity=False)\n",
    "#shap_values = explainer(X_train_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formulation générale de LIME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(training_data= X_train_req.values, feature_names=X_train_req.columns, class_names=['Not Default','Default'], mode='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvegardons le \"explainer\" de \"LIME\" comme un pickle string.\n",
    "#Cette fois-ci en utilisant \"dill\", car \"pickel\" ne fonctionne pas avec \"LIME\"\n",
    "\n",
    "#create an iterator object with write permission - expl.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaebeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('expl_pkl', 'wb') as files:\n",
    "    dill.dump(explainer, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfb5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérification, en réouvrant le \"explainer\" en format \"pickel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('expl_pkl', 'rb') as files:\n",
    "#    explainer_pickle = dill.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb79abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def explain(data_row, predict_fn):\n",
    "#    np.random.seed(16)\n",
    "#    return explainer_pickle.explain_instance(data_row, predict_fn,num_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f648b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a. Résultat/Interprétation/Explication du modèle pour la 2ème ligne du dataset:\n",
    "\n",
    "\n",
    "\n",
    "#ATTENTION:\n",
    "#Les explications des 'features importances' avec LIME sont le résultat d'un processus d'échantillonnage aléatoire, \n",
    "#on ne dois donc pas obtenir exactement la même explication à chaque fois, à moins qu'on définisse le 'random seed' \n",
    "#avant chaque exécution de l''explain_instance'.\n",
    "\n",
    "#Faisons une fonction qui le fasse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b0929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(data_row, predict_fn):\n",
    "    np.random.seed(16)\n",
    "    return explainer.explain_instance(data_row, predict_fn,num_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faisons plusieurs test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78dc2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=explain(X_test_req.iloc[1],lgb_best.predict_proba)\n",
    "\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e268ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=explain(X_test_req.iloc[1],lgb_best.predict_proba)\n",
    "\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfeeb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On a bien le même résultat.\n",
    "\n",
    "#On voit que pour la 2ème ligne, on a:\n",
    "# -un client \"En Défaut\";\n",
    "# -pour lequel les \"valeur en orange\" du dernier tableau, et/ou les valeurs de la colonne \"Not Default\" du tableau du\n",
    "#milieu sont les raisons pour lesquelles le client est considéré comme \"Défaut\".\n",
    "\n",
    "\n",
    "#b. Résultat/Interprétation/Explication du modèle pour la 4ème ligne du dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2daacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=explain(X_test_req.iloc[3],lgb_best.predict_proba)\n",
    "\n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a37629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette fois-ci, le client de la 10ème ligne est considéré comme \"Sain\" compte tenu des features en bleu.\n",
    "\n",
    "\n",
    "#c. Résultat/Interprétation/Explication du modèle pour le client au 'SK_ID_CURR'=150932."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f1a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=X_test_req[X_test_req['SK_ID_CURR']==341512].index[0]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30350a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=explain(X_test_req.iloc[r],lgb_best.predict_proba)\n",
    "\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c39751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d. Cas général: faisant appel à introduire le 'SK_ID_CURR' du client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = float(input('What is your SK_ID_CURR?'))\n",
    "s=X_test_req[X_test_req['SK_ID_CURR']==n].index[0]\n",
    "\n",
    "exp_s=explain(X_test_req.iloc[s],lgb_best.predict_proba)\n",
    "\n",
    "exp_s.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maintenant dans le 'test set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b79247",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = float(input('What is your SK_ID_CURR?'))\n",
    "s=test_df_n[test_df_n['SK_ID_CURR']==n].index[0]\n",
    "\n",
    "exp_s=explain(test_df_n.iloc[s],lgb_best.predict_proba)\n",
    "\n",
    "exp_s.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a319c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae6fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
